{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Load the model.\n",
    "    model = YOLO('yolov8n-oiv7.pt')\n",
    "\n",
    "    # Training with the first ten layers frozen.\n",
    "    results = model.train(\n",
    "        data=r'C:\\Users\\athen\\Desktop\\Thesis\\FullLSyolov8\\data.yaml',\n",
    "        imgsz=640,\n",
    "        epochs=3,\n",
    "        batch=16,\n",
    "        device='cpu',\n",
    "        name='yolov8n_three_class_tester_3e_batch16')\n",
    "\n",
    "\n",
    "model = YOLO('runs/detect/yolov8n_three_class_tester_20lf_lr0.0001_batch16/weights/best.pt')\n",
    "\n",
    "results = model('test_imgs/truck.jpg')\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes  \n",
    "    masks = result.masks  \n",
    "    keypoints = result.keypoints  \n",
    "    probs = result.probs  \n",
    "    obb = result.obb  \n",
    "    result.show()  \n",
    "    result.save(filename=\"test_imgs/truck_20lf_50e.jpg\")  # save to disk\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for webcam, or provide a video file path\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLOv8 inference on the frame\n",
    "    results = model(frame)\n",
    "\n",
    "    # Iterate through the results and render them\n",
    "    for result in results:\n",
    "        frame = result.plot()  # This will draw bounding boxes and labels on the frame\n",
    "\n",
    "    # Display the frame with detections\n",
    "    cv2.imshow('YOLOv8 Fine Tuned Real-Time Object Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop_around_point(image, point, side):\n",
    "    \"\"\"Crops a square around a given point in the image.\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): The input image.\n",
    "        point (tuple): (x, y) coordinates of the center point.\n",
    "        side (int): Length of the square sides.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Cropped square region.\n",
    "    \"\"\"\n",
    "    x, y = int(point[0]), int(point[1])  # Ensure integer coordinates\n",
    "    h, w = image.shape[:2]  # Get image dimensions\n",
    "\n",
    "    # Calculate half side length\n",
    "    half_side = side // 2\n",
    "\n",
    "    # Define crop boundaries\n",
    "    x1, y1 = max(0, x - half_side), max(0, y - half_side)\n",
    "    x2, y2 = min(w, x + half_side), min(h, y + half_side)\n",
    "\n",
    "    # Crop the image\n",
    "    cropped = image[y1:y2, x1:x2]\n",
    "\n",
    "    return cropped\n",
    "\n",
    "def draw_text(image, text):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    lines = []\n",
    "    current_line = \"\"\n",
    "    for word in text.split():\n",
    "        test_line = f\"{current_line} {word}\" if current_line else word\n",
    "        if draw.textlength(test_line, font=font) <= max_width:\n",
    "            current_line = test_line\n",
    "        else:\n",
    "            lines.append(current_line)\n",
    "            current_line = word\n",
    "    if current_line:\n",
    "        lines.append(current_line)\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        draw.text((image.width - margin, margin + i * line_spacing), line, font=font, fill=\"black\", anchor=\"rt\")\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\", verbose=False) \n",
    "genai.configure(api_key=\"AIzaSyA3UzFzEJNv7rFypfl4heRHw6JFhD5UTFA\")  \n",
    "generative_model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")\n",
    "\n",
    "\n",
    "video_path = \"/home/michaelrice/MichaelRiceThesis/sampledata/sample2/gaze_video.mp4\" \n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_delay = int(1000 / video_fps) \n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time() \n",
    "\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  \n",
    "\n",
    "    cv2.imshow(\"Video\", frame)  \n",
    "\n",
    "    key = cv2.waitKey(frame_delay) & 0xFF  \n",
    "\n",
    "    if key == ord('d'): \n",
    "\n",
    "        frame_index = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        gps = gaze_points[frame_index]\n",
    "\n",
    "        results = model(frame)\n",
    "        dets = [model.names[int(detection[5])] for detection in results[0].boxes.data]\n",
    "        non_person_obj = [det for det in dets if det != \"person\"][0]\n",
    "\n",
    "        bboxes = results[0].boxes.xyxy\n",
    "\n",
    "        \n",
    "        for d in dets:\n",
    "            if d == non_person_obj:\n",
    "                bbox = bboxes[dets.index(d)]\n",
    "                x1, y1, x2, y2 = bbox[:4]\n",
    "                cropped_frame = cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                labelled_frame = cv2.putText(cropped_frame, d, (int(x1), int(y1)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        if dets:\n",
    "\n",
    "            prompt = f\"\"\"You are a language model optimized to provide educational information about different types of objects. \n",
    "                        I have detected a {non_person_obj} in the image. Provide educational information about this object in the format: \n",
    "                        \"The detected object is a {non_person_obj}.\" followed by a brief description (no more than 50 tokens). \n",
    "                        Ensure the response is coherent, complete, and informative. Do not include introductory sentences.\n",
    "                    \"\"\"\n",
    "\n",
    "            try:\n",
    "                response = generative_model.generate_content(prompt)\n",
    "                information = response.text.strip() if response.candidates and response.text.strip() else \"No information available.\"\n",
    "            except Exception as e:\n",
    "                information = \"Failed to generate information.\"\n",
    "\n",
    "\n",
    "            image = Image.fromarray(frame)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "\n",
    "            font = ImageFont.load_default(size = 48)  # Use default font\n",
    "            margin = 30\n",
    "            x = image.width - margin\n",
    "            y = margin\n",
    "            line_spacing = 36\n",
    "            max_width = image.width // 2\n",
    "\n",
    "            lines = []\n",
    "            current_line = \"\"\n",
    "            for word in information.split():\n",
    "                test_line = f\"{current_line} {word}\" if current_line else word\n",
    "                if draw.textlength(test_line, font=font) <= max_width:\n",
    "                    current_line = test_line\n",
    "                else:\n",
    "                    lines.append(current_line)\n",
    "                    current_line = word\n",
    "            if current_line:\n",
    "                lines.append(current_line)\n",
    "\n",
    "            for i, line in enumerate(lines):\n",
    "                text_bbox = draw.textbbox((0, 0), line, font=font)\n",
    "                text_width = text_bbox[2] - text_bbox[0]\n",
    "                text_height = text_bbox[3] - text_bbox[1]\n",
    "                draw.text(((image.width - text_width) / 2, y + i * line_spacing), line, font=font, fill=\"black\")\n",
    "\n",
    "\n",
    "            frame = np.array(image)\n",
    "\n",
    "\n",
    "        cv2.imshow(\"Video\", frame) \n",
    "        cv2.waitKey(0) \n",
    "\n",
    "    elif key == ord('q'): \n",
    "        break\n",
    "\n",
    "    elapsed_time = (time.time() - start_time) * 1000  \n",
    "    remaining_time = max(1, frame_delay - int(elapsed_time))  \n",
    "    cv2.waitKey(remaining_time)  \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
